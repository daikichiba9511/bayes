{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stanと ~R~ Pythonでベイズ統計モデリング\n",
    "\n",
    "このノートブックではwaicやwbicの情報量基準をみていく\n",
    "\n",
    "実装は[このノートブックを参考にした](https://gist.github.com/narrowlyapplicable/580f2d3610190b7bc04693466e409224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystan\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = 8\n",
    "y = np.array([28.,  8., -3.,  7., -1.,  1., 18., 12.])\n",
    "sigma = np.array([15., 10., 16., 11.,  9., 11., 10., 18.])\n",
    "schools = np.array(['Choate', 'Deerfield', 'Phillips Andover', 'Phillips Exeter',\n",
    "                    'Hotchkiss', 'Lawrenceville', \"St. Paul's\", 'Mt. Hermon'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model\n",
    "\n",
    "モデルは０１で使ったモデルをそのまま使う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_model = \"\"\"\n",
    "data {\n",
    "  int<lower=0> J;\n",
    "  real y[J];\n",
    "  real<lower=0> sigma[J];\n",
    "}\n",
    "\n",
    "parameters {\n",
    "  real mu;\n",
    "  real<lower=0> tau;\n",
    "  real theta[J];\n",
    "}\n",
    "\n",
    "model {\n",
    "  mu ~ normal(0, 5);\n",
    "  tau ~ cauchy(0, 5);\n",
    "  theta ~ normal(mu, tau);\n",
    "  y ~ normal(theta, sigma);\n",
    "}\n",
    "generated quantities {\n",
    "    vector[J] log_lik;\n",
    "    vector[J] y_hat;\n",
    "    for (j in 1:J) {\n",
    "        log_lik[j] = normal_lpdf(y[j] | theta[j], sigma[j]);\n",
    "        y_hat[j] = normal_rng(theta[j], sigma[j]);\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stanモデルをコンパイルする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL model_code_b0eada194ad938e30ed47926216f98ca NOW.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(\"./model_code.pkl\", \"rb\") as f:\n",
    "        stanmodel = pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    stanmodel = pystan.StanModel(model_code=schools_model, model_name=\"model_code\")\n",
    "    with open(\"./model_code.pkl\", \"wb\") as f:\n",
    "        pickle.dump(stanmodel, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_dat = {'J': 8,\n",
    "               'y': [28,  8, -3,  7, -1,  1, 18, 12],\n",
    "               'sigma': [15, 10, 16, 11,  9, 11, 10, 18]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:54 of 3600 iterations ended with a divergence (1.5 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.8 to remove the divergences.\n",
      "WARNING:pystan:Chain 2: E-BFMI = 0.184\n",
      "WARNING:pystan:Chain 3: E-BFMI = 0.15\n",
      "WARNING:pystan:E-BFMI below 0.2 indicates you may need to reparameterize your model\n"
     ]
    }
   ],
   "source": [
    "fit = sm.sampling(data=schools_dat, iter=1000, chains=4, warmup=100, seed=496)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Def waic\n",
    "\n",
    "ここ実装に自信ないので間違いあったら教えてください。。\n",
    "\n",
    "渡辺ベイズp１１８参照\n",
    "\n",
    "waic: $$W_n = T_n + \\frac{\\beta V_n}{n} \\tag{1}$$\n",
    "\n",
    "経験損失： $$\\displaystyle{V_n = \\sum_{i=1}^{n} {{E_w}[(log p(X_i|w))^2)] - {E_w}[log p(X_i|w)]^2  }}\\tag{2}$$\n",
    "\n",
    "汎化数分散： $$\\displaystyle{T_n = - \\frac{1}{n} \\sum_{i=1}^{n} log E_w[p(X_i|w)] }\\tag{3}$$\n",
    "\n",
    "[wbicは詳しくは渡辺先生のHPのこのページか](http://watanabe-www.math.dis.titech.ac.jp/users/swatanab/wbic2012.html)\n",
    "[このページ](http://watanabe-www.math.dis.titech.ac.jp/users/swatanab/waicwbic_e.html*)\n",
    "\n",
    "$$wbic = E_w^{\\frac{1}{log\\ n}} \\left[\\displaystyle{\\sum_{i=1}^{n}} log p(X_i|w)\\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_waic(samples, beta=1):\n",
    "    \"\"\"\n",
    "    ==params==\n",
    "    samples: 対数尤度　log p(X_i|w)\n",
    "    beta : 逆温度\n",
    "    ==return==\n",
    "    waic : \n",
    "    \"\"\"\n",
    "    Tn = -np.mean(np.log(np.mean(np.exp(samples), axis=0)))\n",
    "    print(\"Tn:\",Tn)\n",
    "    Vn = np.sum(np.mean(samples**2, axis=0) - np.mean(samples, axis=0)**2)\n",
    "    print(\"Vn\",Vn)\n",
    "    waic = Tn + beta * (Vn/samples.shape[0])\n",
    "    print(\"waic\", waic)\n",
    "    return waic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_wbic(samples):\n",
    "    \"\"\"\n",
    "    ==params==\n",
    "    samples: 対数尤度　log p(X_i|w)\n",
    "    beta : 逆温度\n",
    "    ==return==\n",
    "    wbic :\n",
    "    \"\"\"\n",
    "    beta = 1/np.log(samples.shape[0])\n",
    "    wbic = - np.mean(beta * np.sum(samples, axis=1))\n",
    "    print(\"wbic\",wbic)\n",
    "    return wbic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:30 of 2800 iterations ended with a divergence (1.07 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.8 to remove the divergences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tn: 3.727941745883408\n",
      "Vn 0.8458107535515627\n",
      "waic 3.7282438211525335\n",
      "wbic 3.803773481546461\n"
     ]
    }
   ],
   "source": [
    "standata = schools_dat\n",
    "fit = sm.sampling(data=standata, iter=1000, warmup=300, seed=496)\n",
    "ms = fit.extract()\n",
    "waic = calc_waic(ms[\"log_lik\"])\n",
    "wbic = calc_wbic(ms[\"log_lik\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WAICやWBICといった情報量基準は、パラメータの事後分布が正規分布で、尤度関数が凸じゃなくても使える。\n",
    "\n",
    "が、あくまでもモデル間での比較基準に過ぎないことを覚えておきたい。\n",
    "\n",
    "真のモデルに近いのを選択するには、一致性をもつWBICを用いるらしい。。（まだわかってない。）\n",
    "\n",
    "次はモデリング時の基準となる情報量基準について、実装を確認したので、次はモデリング部分についてやっていきたい"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
