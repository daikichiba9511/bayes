{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stanと ~R~ Pythonでベイズ統計モデリング\n",
    "## Stanの基本的な文法\n",
    "\n",
    "\n",
    "data{<br>データの宣言<br>}<br>parameters{<br>サンプリングしたいパラメータ$\\theta$<br>}\n",
    "<br><br>model{<br>尤度$p(Y|\\theta)$<br>事前分布$p(\\theta)$<br>}\n",
    "\n",
    "### memo\n",
    "\n",
    "- stanでは、値が決まってなく、確率変数とみなせるものは全てparametersにいれる。\n",
    "- 渡辺ベイズによると、データが確率変数の観測値としてみなせるために、事後分布なんかも確率変数と言うこと。\n",
    "- 確率モデル、事前分布も自分で定義するもので事後分布も定義してるとみなす。\n",
    "\n",
    "- 著者によるとモデリングのコツは、\n",
    "     1. 最初にモデル部分を記述する\n",
    "     2. それから、dataにデータの変数を記述、残りをparametersに記述\n",
    "\n",
    "の流れで無理に初めから埋めていかないことがコツらしい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  トイデータで試してみる\n",
    "\n",
    "$$\\begin{eqnarray}Y &\\sim& Nonmal(\\mu, 1) \\\\ \\mu &\\sim& Normal(0, 100)\\end{eqnarray}$$\n",
    "\n",
    "のモデルで、StanでMCMC(Nuts)を使ってパラメータの事後分布を実現させる。\n",
    "\n",
    "Stanの開発者は、Stringでの記述よりは.Stanファイルに記述することを勧めてる\n",
    "\n",
    "ここではファイルを分けると行き来がめんどくさいのでStringでモデルを記述する。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystan\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"\"\"\n",
    "\n",
    "data{\n",
    "    int<lower=0> N; // データの数\n",
    "    real Y[N];\n",
    "}\n",
    "\n",
    "parameters{\n",
    "    real mu;\n",
    "}\n",
    "\n",
    "model{\n",
    "    for (n in 1:N) {\n",
    "        Y[n] ~ normal(mu, 1); // normal(mean, std)に注意\n",
    "    }\n",
    "    \n",
    "    mu ~ normal(0, 100);\n",
    "}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complie モデルのコンパイル。時間がかかる。\n",
    "sm = pystan.StanModel(model_code=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"N\":8, \"Y\":[15, 10, 16, 11, 9, 11, 10, 18]}\n",
    "fit = sm.sampling(\n",
    "        data=data, iter=1000, chains=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(data[\"Y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## arvizで予測分布まで"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = 8\n",
    "y = np.array([28.,  8., -3.,  7., -1.,  1., 18., 12.])\n",
    "sigma = np.array([15., 10., 16., 11.,  9., 11., 10., 18.])\n",
    "schools = np.array(['Choate', 'Deerfield', 'Phillips Andover', 'Phillips Exeter',\n",
    "                    'Hotchkiss', 'Lawrenceville', \"St. Paul's\", 'Mt. Hermon'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_model = \"\"\"\n",
    "data {\n",
    "  int<lower=0> J;\n",
    "  real y[J];\n",
    "  real<lower=0> sigma[J];\n",
    "}\n",
    "\n",
    "parameters {\n",
    "  real mu;\n",
    "  real<lower=0> tau;\n",
    "  real theta[J];\n",
    "}\n",
    "\n",
    "model {\n",
    "  mu ~ normal(0, 5);\n",
    "  tau ~ cauchy(0, 5);\n",
    "  theta ~ normal(mu, tau);\n",
    "  y ~ normal(theta, sigma);\n",
    "}\n",
    "generated quantities {\n",
    "    vector[J] log_lik;\n",
    "    vector[J] y_hat;\n",
    "    for (j in 1:J) {\n",
    "        log_lik[j] = normal_lpdf(y[j] | theta[j], sigma[j]);\n",
    "        y_hat[j] = normal_rng(theta[j], sigma[j]);\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "schools_dat = {'J': 8,\n",
    "               'y': [28,  8, -3,  7, -1,  1, 18, 12],\n",
    "               'sigma': [15, 10, 16, 11,  9, 11, 10, 18]}\n",
    "\n",
    "\n",
    "sm = pystan.StanModel(model_code=schools_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = sm.sampling(data=schools_dat, iter=1000, chains=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- パラメータの事後分布の可視化にはpystanではarvizを使う。\n",
    "\n",
    "今回MCMCサンプリングしたあとの結果をfitに格納しているので```fit.plot()```もできるがwarningがでて\n",
    "\n",
    "```arviz```を使うよう勧められる。\n",
    "\n",
    "インストールはanacondaを使っていれば```conda install -c conda-forge arviz```\n",
    "\n",
    "使い方詳しくは[公式](https://arviz-devs.github.io/arviz/notebooks/Introduction.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.style.use(\"arviz-darkgrid\")\n",
    "az.plot_posterior(fit);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(fit);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_density(fit);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今まではパラメータの事後分布$p(w|X) \\propto p(X|w)p(w)$をMCMCサンプリングで近似的に求めたので、\n",
    "\n",
    "そのパラメータの事後分布で確率モデルを平均した予測分布$p(x^*|X)=\\int p(x*|w)p(w|X)$を求める。\n",
    "\n",
    "ベイズ推定による統計モデリングでは、この予測分布とサンプルを発生している真の確率分布との誤差（汎化誤差）を小さくすることを目指す。\n",
    "\n",
    "詳しくは、[ベイズ統計の理論と方法](http://watanabe-www.math.dis.titech.ac.jp/users/swatanab/bayes-theory-method.html)や[著者HPの講義資料やQA](http://watanabe-www.math.dis.titech.ac.jp/users/swatanab/index-j.html)を参照。\n",
    "\n",
    "- [arviz.from_pystan document](https://arviz-devs.github.io/arviz/generated/arviz.from_pystan.html)\n",
    "\n",
    "    - ```cords``` : インデックスとして使われてる値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = az.from_pystan(\n",
    "    posterior=fit,\n",
    "    posterior_predictive='y_hat',\n",
    "    observed_data=['y'],\n",
    "    log_likelihood={'y': 'log_lik'},\n",
    "    coords={'school': schools},\n",
    "    dims={\n",
    "        'theta': ['school'],\n",
    "        'y': ['school'],\n",
    "        'log_lik': ['school'],\n",
    "        'y_hat': ['school'],\n",
    "        'theta_tilde': ['school']\n",
    "    }\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_pair(inference_dist, coords={'school': ['Choate', 'Deerfield', 'Phillips Andover']}, divergences=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = az.convert_to_inference_data(fit)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}